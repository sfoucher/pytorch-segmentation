# -*- coding: utf-8 -*-
"""DeepLabv3-quickstart.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/sfoucher/60b7fa43e685883a8f30c0118f0e6e72/deeplabv3-quickstart.ipynb
"""

!nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# pip3 --quiet install  torch torchvision pillow gitpython lz4 matplotlib numpy pyyaml scikit-learn six tqdm h5py opencv-python googledrivedownloader
# pip3 --quiet install affine geojson shapely pyproj
# pip uninstall thelper
# rm -rf ./thelper
# git clone https://github.com/sfoucher/thelper
# cd thelper
# pip install -v -e .

# Commented out IPython magic to ensure Python compatibility.
!pip install pyyaml yamlmagic
# %load_ext yamlmagic

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# pip --quiet install pretrainedmodels albumentations opencv-python opencv-contrib-python pyyaml
# git clone https://github.com/sfoucher/pytorch-segmentation

import os
os.kill(os.getpid(), 9)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import os
import numpy as np
import cv2 as cv
import torch
import torchvision
import zipfile
import tarfile
import matplotlib
import matplotlib.pyplot as plt
import sklearn.metrics
import time
import collections
import tqdm
import json
import requests
import zipfile
import gdal
import thelper
import sys
sys.path.append('/content/pytorch-segmentation/src')

from google_drive_downloader import GoogleDriveDownloader as gdd
import os.path as osp
import sys


def maybe_download_and_extract(file_id, dest_path):
    filename = dest_path.split('/')[-1]
    file_path = dest_path
    download_dir= osp.dirname(osp.abspath(dest_path))
    if not os.path.isfile(dest_path):
      gdd.download_file_from_google_drive(file_id= file_id, dest_path= file_path)
      print("Download finished. Extracting files.")

      if file_path.endswith(".zip"):
          # Unpack the zip-file.
          zipfile.ZipFile(file=file_path, mode="r").extractall(download_dir)
      elif file_path.endswith((".tar.gz", ".tgz")):
          # Unpack the tar-ball.
          tarfile.open(name=file_path, mode="r:gz").extractall(download_dir)
      print("Done.")
    else:
        print("Data has apparently already been downloaded and unpacked.")
maybe_download_and_extract(file_id="1zyqOXH5G2I-iZCYIkt1EMDrDgnXKUD17", dest_path="/content/pytorch-segmentation/data/dataset.tar.gz")

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cd /content/pytorch-segmentation/tf_model
# wget http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz
# tar -xvf deeplabv3_cityscapes_train_2018_02_06.tar.gz
# cd ../src
# python -m converter.convert_xception65 ../tf_model/deeplabv3_cityscapes_train/model.ckpt 19 ../model/cityscapes_deeplab_v3_plus/model.pth

# Commented out IPython magic to ensure Python compatibility.
# load the magic 
# %load_ext yamlmagic

import sys
sys.path.append('/content/pytorch-segmentation/src')

!cd /content/pytorch-segmentation/src
from models.net import EncoderDecoderNet, SPPNet
from losses.multi import MultiClassCriterion
from logger.log import debug_logger
from logger.plot import history_ploter
from utils.optimizer import create_optimizer
from utils.metrics import compute_iou_batch
import yaml
import pickle
import argparse
import yaml
import numpy as np
import albumentations as albu
from collections import OrderedDict
from pathlib import Path
from tqdm import tqdm

# Commented out IPython magic to ensure Python compatibility.
# %%yaml config
# Net:
#   enc_type: 'xception65'
#   dec_type: 'unet'
#   output_stride: 8
#   output_channels: 19
# Data:
#   dataset: 'deepglobe-dynamic'
#   target_size: (512, 512)
# Train:
#   max_epoch: 500
#   batch_size: 4
#   fp16: True
#   resume: False
#   pretrained_path: '/content/pytorch-segmentation/model/cityscapes_deeplab_v3_plus/model.pth'
#   freeze: True
#   seed: False
# Loss:
#   loss_type: 'Lovasz'
# Optimizer:
#   mode: 'sgd'
#   base_lr: 0.007
#   t_max: 30

"""### Prepare Training"""

#config_path = '/content/pytorch-segmentation/config/deepglobe_deeplabv3_weights-cityscapes_19-outputs_small-patches_dynamic.yaml'

#with open(config_path) as yaml_file:
#  config = yaml.load(yaml_file)
net_config = config['Net']
data_config = config['Data']
train_config = config['Train']
loss_config = config['Loss']
opt_config = config['Optimizer']
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
t_max = opt_config['t_max']

# Collect training parameters
max_epoch = train_config['max_epoch']
batch_size = train_config['batch_size']
fp16 = train_config['fp16']
resume = train_config['resume']
pretrained_path = train_config['pretrained_path']
freeze_enabled = train_config['freeze']
seed_enabled = train_config['seed']
dataset_base_dir = '/content/pytorch-segmentation/data/deepglobe_as_pascalvoc/VOCdevkit/VOC2012'
#########################################
# Deterministic training
if seed_enabled:
    seed = 100
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed=seed)
    import random
    random.seed(a=100)
#########################################

# Network
if 'unet' in net_config['dec_type']:
    net_type = 'unet'
    net_config.pop('output_stride')
    net_config['dec_type']= 'unet_scse'
    net_config['enc_type']= 'resnet18'
    model = EncoderDecoderNet(**net_config)
else:
    net_type = 'deeplab'
    model = SPPNet(**net_config)

dataset = data_config['dataset']
print(dataset)
if dataset == 'pascal':
    from dataset.pascal_voc import PascalVocDataset as Dataset
    net_config['output_channels'] = 21
    classes = np.arange(1, 22)
elif dataset == 'cityscapes':
    from dataset.cityscapes import CityscapesDataset as Dataset
    net_config['output_channels'] = 19
    classes = np.arange(1, 20)
elif dataset == 'deepglobe-dynamic':
    from dataset.deepglobe_dynamic import DeepGlobeDatasetDynamic as Dataset
    net_config['output_channels'] = 7
    classes = np.arange(1, 8)
else:
    raise NotImplementedError
del data_config['dataset']

modelname = 'test' #config_path.stem
output_dir = Path('/content/pytorch-segmentation/model') / modelname
output_dir.mkdir(exist_ok=True)
log_dir = Path('/content/pytorch-segmentation/logs') / modelname
log_dir.mkdir(exist_ok=True)

logger = debug_logger(log_dir)
logger.debug(config)
logger.info(f'Device: {device}')
logger.info(f'Max Epoch: {max_epoch}')

# Loss
loss_fn = MultiClassCriterion(**loss_config).to(device)
params = model.parameters()
optimizer, scheduler = create_optimizer(params, **opt_config)

# history
if resume:
    with open(log_dir.joinpath('history.pkl'), 'rb') as f:
        history_dict = pickle.load(f)
        best_metrics = history_dict['best_metrics']
        loss_history = history_dict['loss']
        iou_history = history_dict['iou']
        start_epoch = len(iou_history)
        for _ in range(start_epoch):
            scheduler.step()
else:
    start_epoch = 0
    best_metrics = 0
    loss_history = []
    iou_history = []

# Dataset
affine_augmenter = albu.Compose([albu.HorizontalFlip(p=.5),
                                 # Rotate(5, p=.5)
                                 ])
# image_augmenter = albu.Compose([albu.GaussNoise(p=.5),
#                                 albu.RandomBrightnessContrast(p=.5)])
image_augmenter = None
"""
train_dataset = Dataset(base_dir= '/content/pytorch-segmentation/data/deepglobe_as_pascalvoc/VOCdevkit/VOC2012',
                        affine_augmenter=affine_augmenter, image_augmenter=image_augmenter,
                        net_type=net_type, **data_config)
valid_dataset = Dataset(base_dir= '/content/pytorch-segmentation/data/deepglobe_as_pascalvoc/VOCdevkit/VOC2012',
                        split='valid', net_type=net_type, **data_config)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4,
                          pin_memory=True, drop_last=True)
valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)
"""

# To device
model = model.to(device)
# Pretrained model
if 'unet' not in net_config['dec_type'] and pretrained_path:
    logger.info(f'Resume from {pretrained_path}')
    param = torch.load(pretrained_path)
    model.load_state_dict(param)
    del param

    #########################################
    if freeze_enabled:
        # Code de RÃ©mi
        # Freeze layers
        for param_index in range(int((len(optimizer.param_groups[0]['params'])) * 0.5)):
            optimizer.param_groups[0]['params'][param_index].requires_grad = False
    #########################################

# fp16
if fp16:
    # I only took the necessary files because I don't need the C backend of apex,
    # which is broken and can't be installed
    # from apex import fp16_utils
    from utils.apex.apex.fp16_utils.fp16util import BN_convert_float
    from utils.apex.apex.fp16_utils.fp16_optimizer import FP16_Optimizer
    # model = fp16_utils.BN_convert_float(model.half())
    model = BN_convert_float(model.half())
    # optimizer = fp16_utils.FP16_Optimizer(optimizer, verbose=False, dynamic_loss_scale=True)
    optimizer = FP16_Optimizer(optimizer, verbose=False, dynamic_loss_scale=True)
    logger.info('Apply fp16')

# Restore model
if resume:
    model_path = output_dir.joinpath(f'model_tmp.pth')
    logger.info(f'Resume from {model_path}')
    param = torch.load(model_path)
    model.load_state_dict(param)
    del param
    opt_path = output_dir.joinpath(f'opt_tmp.pth')
    param = torch.load(opt_path)
    optimizer.load_state_dict(param)
    del param

from torch.utils.data import DataLoader
import torch.nn.functional as F

# Train
for i_epoch in range(start_epoch, max_epoch):
    logger.info(f'Epoch: {i_epoch}')
    logger.info(f'Learning rate: {optimizer.param_groups[0]["lr"]}')

    train_losses = []
    train_ious = []
    model.train()

    # Initialize randomized but balanced datasets
    train_dataset = Dataset(base_dir = dataset_base_dir,
                            affine_augmenter=affine_augmenter, image_augmenter=image_augmenter,
                            net_type=net_type, **data_config)
    valid_dataset = Dataset(base_dir = dataset_base_dir,
                            split='valid', net_type=net_type, **data_config)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4,
                              pin_memory=True, drop_last=True)
    valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)

    with tqdm(train_loader) as _tqdm:
        for batched in _tqdm:
            images, labels = batched
            if fp16:
                images = images.half()
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            preds = model(images)
            if net_type == 'deeplab':
                preds = F.interpolate(preds, size=labels.shape[1:], mode='bilinear', align_corners=True)
            if fp16:
                loss = loss_fn(preds.float(), labels)
            else:
                loss = loss_fn(preds, labels)

            preds_np = preds.detach().cpu().numpy()
            labels_np = labels.detach().cpu().numpy()
            iou = compute_iou_batch(np.argmax(preds_np, axis=1), labels_np, classes)

            _tqdm.set_postfix(OrderedDict(seg_loss=f'{loss.item():.5f}', iou=f'{iou:.3f}'))
            train_losses.append(loss.item())
            train_ious.append(iou)

            if fp16:
                optimizer.backward(loss)
            else:
                loss.backward()
            optimizer.step()

    scheduler.step()

    train_loss = np.mean(train_losses)
    train_iou = np.nanmean(train_ious)
    logger.info(f'train loss: {train_loss}')
    logger.info(f'train iou: {train_iou}')

    torch.save(model.state_dict(), output_dir.joinpath('model_tmp.pth'))
    torch.save(optimizer.state_dict(), output_dir.joinpath('opt_tmp.pth'))

    valid_losses = []
    valid_ious = []
    model.eval()
    with torch.no_grad():
        with tqdm(valid_loader) as _tqdm:
            for batched in _tqdm:
                images, labels = batched
                if fp16:
                    images = images.half()
                images, labels = images.to(device), labels.to(device)
                preds = model.tta(images, net_type=net_type)
                if fp16:
                    loss = loss_fn(preds.float(), labels)
                else:
                    loss = loss_fn(preds, labels)

                preds_np = preds.detach().cpu().numpy()
                labels_np = labels.detach().cpu().numpy()

                # I changed a parameter in the compute_iou method to prevent it from yielding nans
                iou = compute_iou_batch(np.argmax(preds_np, axis=1), labels_np, classes)

                _tqdm.set_postfix(OrderedDict(seg_loss=f'{loss.item():.5f}', iou=f'{iou:.3f}'))
                valid_losses.append(loss.item())
                valid_ious.append(iou)

    valid_loss = np.mean(valid_losses)
    valid_iou = np.mean(valid_ious)
    logger.info(f'valid seg loss: {valid_loss}')
    logger.info(f'valid iou: {valid_iou}')

    if best_metrics < valid_iou:
        best_metrics = valid_iou
        logger.info('Best Model!')
        torch.save(model.state_dict(), output_dir.joinpath('model.pth'))
        torch.save(optimizer.state_dict(), output_dir.joinpath('opt.pth'))

    loss_history.append([train_loss, valid_loss])
    iou_history.append([train_iou, valid_iou])
    history_ploter(loss_history, log_dir.joinpath('loss.png'))
    history_ploter(iou_history, log_dir.joinpath('iou.png'))

    history_dict = {'loss': loss_history,
                    'iou': iou_history,
                    'best_metrics': best_metrics}
    with open(log_dir.joinpath('history.pkl'), 'wb') as f:
        pickle.dump(history_dict, f)

with tqdm(train_loader) as _tqdm:
  for batched in _tqdm:
      images, labels = batched
      if fp16:
          images = images.half()
      images, labels = images.to(device), labels.to(device)
      optimizer.zero_grad()
      preds = model(images)
      if net_type == 'deeplab':
          preds = F.interpolate(preds, size=labels.shape[1:], mode='bilinear', align_corners=True)
      if fp16:
          loss = loss_fn(preds.float(), labels)
      else:
          loss = loss_fn(preds, labels)

      preds_np = preds.detach().cpu().numpy()
      labels_np = labels.detach().cpu().numpy()
      iou = compute_iou_batch(np.argmax(preds_np, axis=1), labels_np, classes)

      _tqdm.set_postfix(OrderedDict(seg_loss=f'{loss.item():.5f}', iou=f'{iou:.3f}'))
      train_losses.append(loss.item())
      train_ious.append(iou)

      if fp16:
          optimizer.backward(loss)
      else:
          loss.backward()
      optimizer.step()

print(pretrained_path)